{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento: Transcripci√≥n con Whisper 'large' en GPU (Colab)\n",
        "\n",
        "Este cuaderno te gu√≠a paso a paso para ejecutar el modelo `large` de OpenAI Whisper en una GPU gratuita de Google Colab. El objetivo es replicar un experimento b√°sico para:\n",
        "\n",
        "1.  **Medir el tiempo de carga** del modelo `large`.\n",
        "2.  **Medir el tiempo de transcripci√≥n** de un archivo de audio de ejemplo.\n",
        "3.  **Observar el uso de recursos** (VRAM de la GPU y RAM del sistema).\n",
        "4.  **Evaluar la calidad** de la transcripci√≥n resultante.\n",
        "\n",
        "Est√° basado en el proyecto [Audio-WhatsApp-a-texto](https://github.com/ilahuerta-IA/Audio-WhatsApp-a-texto), utilizando algunos de sus m√≥dulos auxiliares.\n",
        "\n",
        "**¬°Importante!** Aseg√∫rate de haber configurado el entorno de ejecuci√≥n para usar una **GPU** (`Entorno de ejecuci√≥n` -> `Cambiar tipo de entorno de ejecuci√≥n` -> `GPU`)."
      ],
      "metadata": {
        "id": "woYfwDuzQ5Dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVusWNNlDOVT"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Celda 2: Verificar GPU y Clonar Repositorio Base\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Verificar si la GPU est√° disponible\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
        "    DEVICE = \"cuda\"\n",
        "else:\n",
        "    print(\"ADVERTENCIA: No se detect√≥ GPU. Selecciona una GPU en 'Entorno de ejecuci√≥n'.\")\n",
        "    print(\"El modelo 'large' NO funcionar√° razonablemente en CPU.\")\n",
        "    DEVICE = \"cpu\" # Continuar en CPU es solo para fines demostrativos del c√≥digo\n",
        "\n",
        "# Clonar el repositorio original que contiene los m√≥dulos auxiliares\n",
        "# (solo necesitamos audio_handler.py y config.py de √©l)\n",
        "repo_url = \"https://github.com/ilahuerta-IA/Audio-WhatsApp-a-texto.git\"\n",
        "repo_name = \"Audio-WhatsApp-a-texto\"\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Clonando repositorio desde {repo_url}...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Directorio '{repo_name}' ya existe.\")\n",
        "\n",
        "# Cambiar al directorio del repositorio clonado\n",
        "try:\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"Directorio de trabajo cambiado a: {os.getcwd()}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: No se pudo cambiar al directorio '{repo_name}'. ¬øFall√≥ la clonaci√≥n?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 1: Instalar Dependencias\n",
        "\n",
        "Necesitamos instalar algunas herramientas:\n",
        "*   `ffmpeg`: Esencial para que `pydub` pueda leer y convertir diferentes formatos de audio.\n",
        "*   `openai-whisper`: La librer√≠a principal para la transcripci√≥n.\n",
        "*   `pydub`: Para manejar la conversi√≥n de audio a WAV, formato preferido por Whisper."
      ],
      "metadata": {
        "id": "kXvA36rqRodT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 4: Instalar ffmpeg, whisper y pydub\n",
        "\n",
        "print(\"Instalando ffmpeg...\")\n",
        "!apt-get update -qq && apt-get install -y ffmpeg -qq\n",
        "print(\"Instalando openai-whisper y pydub...\")\n",
        "!pip install -U openai-whisper pydub -q\n",
        "\n",
        "print(\"\\nDependencias instaladas.\")"
      ],
      "metadata": {
        "id": "FgixeDImD1O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 2: Sube tu Archivo de Audio\n",
        "\n",
        "Ahora es el momento de **subir tu propio archivo de audio** a Colab.\n",
        "\n",
        "1.  Mira el panel de la izquierda y busca el icono de **Carpeta** (`Archivos`).\n",
        "2.  Haz clic en el icono **Subir** (üìÑ‚Üë).\n",
        "3.  Selecciona el archivo de audio desde tu ordenador (`.mp3`, `.wav`, `.m4a`, `.ogg`, etc.).\n",
        "4.  Espera a que termine la subida. El archivo aparecer√° en el panel de archivos, normalmente en la carpeta `/content/` (o dentro de la carpeta `Audio-WhatsApp-a-texto` si la ten√≠as seleccionada al subir).\n",
        "5.  **¬°MUY IMPORTANTE!** Haz clic derecho sobre el archivo subido y selecciona **`Copiar ruta`**. Necesitar√°s esta ruta en la siguiente celda."
      ],
      "metadata": {
        "id": "AHRsdfyJSOvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 6: Configurar Experimento y Cargar M√≥dulos\n",
        "\n",
        "import pathlib\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# --- ¬°¬°MODIFICA ESTA L√çNEA CON LA RUTA DE TU ARCHIVO!! ---\n",
        "# Pega aqu√≠ la ruta que copiaste en el paso anterior.\n",
        "# Ejemplo: \"/content/mi_audio_subido.mp3\" o \"/content/Audio-WhatsApp-a-texto/mi_audio.wav\"\n",
        "RUTA_AUDIO_ORIGINAL_STR = \"/content/mi_audio.wav\" # <-- ¬°¬°CAMBIA ESTO!!\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "MODELO_A_PROBAR = \"large\"\n",
        "# La Tesla T4 soporta FP16, puede ser m√°s r√°pido y usar menos VRAM.\n",
        "# Ponlo en False si quieres comparar o si usas una GPU m√°s antigua (como K80).\n",
        "USE_FP16 = False if DEVICE == \"cpu\" else True # Usar True por defecto en GPU\n",
        "\n",
        "# --- A√±adir directorio actual (donde est√°n los .py clonados) a sys.path ---\n",
        "repo_directorio = os.getcwd() # Ya estamos dentro del dir clonado\n",
        "if repo_directorio not in sys.path:\n",
        "    sys.path.insert(0, repo_directorio)\n",
        "    print(f\"Directorio '{repo_directorio}' a√±adido a sys.path.\")\n",
        "\n",
        "# --- Importar M√≥dulos Auxiliares ---\n",
        "try:\n",
        "    import audio_handler\n",
        "    import config\n",
        "    print(\"M√≥dulos auxiliares importados correctamente.\")\n",
        "except ImportError as e:\n",
        "    print(f\"ERROR importando m√≥dulos: {e}. Aseg√∫rate de estar en el directorio correcto.\")\n",
        "\n",
        "# --- Validar Ruta y Crear Variables ---\n",
        "try:\n",
        "    ruta_audio_original = pathlib.Path(RUTA_AUDIO_ORIGINAL_STR)\n",
        "    if not ruta_audio_original.is_file():\n",
        "         raise FileNotFoundError(f\"¬°Archivo no encontrado en la ruta especificada! Verifica RUTA_AUDIO_ORIGINAL_STR.\")\n",
        "    else:\n",
        "        print(f\"Archivo de audio a procesar: {ruta_audio_original}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error con la ruta del archivo: {e}\")\n",
        "    ruta_audio_original = None\n",
        "\n",
        "# Variables para resultados\n",
        "modelo_cargado = None\n",
        "ruta_audio_wav = None\n",
        "tiempo_carga_modelo = 0\n",
        "tiempo_transcripcion = 0\n",
        "resultado_transcripcion = None\n",
        "\n",
        "print(f\"\\nConfiguraci√≥n lista. Modelo a usar: '{MODELO_A_PROBAR}', Dispositivo: {DEVICE}, FP16: {USE_FP16}\")"
      ],
      "metadata": {
        "id": "Y-wq9yLyD-jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 3: Convertir Audio a WAV\n",
        "\n",
        "Whisper funciona mejor con archivos WAV. Usaremos el m√≥dulo `audio_handler` (del repositorio base) para convertir tu archivo subido a un formato WAV temporal est√°ndar."
      ],
      "metadata": {
        "id": "QsQNCKaWSqwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 8: Convertir a WAV\n",
        "\n",
        "if ruta_audio_original:\n",
        "    print(f\"Convirtiendo {ruta_audio_original.name} a WAV temporal...\")\n",
        "    start_time_convert = time.time()\n",
        "    ruta_audio_wav = audio_handler.convert_to_wav_if_needed(ruta_audio_original)\n",
        "    end_time_convert = time.time()\n",
        "\n",
        "    if ruta_audio_wav and ruta_audio_wav.exists():\n",
        "        print(f\"Audio convertido a: {ruta_audio_wav} en {end_time_convert - start_time_convert:.2f} segundos.\")\n",
        "    else:\n",
        "        print(\"Error: Fall√≥ la conversi√≥n a WAV.\")\n",
        "else:\n",
        "    print(\"Error: No hay ruta de audio original v√°lida para convertir.\")"
      ],
      "metadata": {
        "id": "cJf5RI2UFWtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 4: Cargar Modelo Whisper 'large'\n",
        "\n",
        "Ahora cargaremos el modelo `large` en la memoria de la GPU (o CPU si no hay GPU). Mediremos cu√°nto tiempo tarda este proceso.\n",
        "\n",
        "**¬°Atenci√≥n!** Durante la ejecuci√≥n de esta celda:\n",
        "*   **Observa los indicadores `RAM` y `GPU RAM`** en la esquina superior derecha de Colab. Anota el uso m√°ximo que veas.\n",
        "*   Whisper descargar√° el modelo si es la primera vez que se usa en esta sesi√≥n (puede tardar un poco)."
      ],
      "metadata": {
        "id": "IJptwc5pSzsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 10: Cargar Modelo y Medir Tiempo/Recursos\n",
        "\n",
        "import whisper # Asegurarnos de importar la librer√≠a principal\n",
        "\n",
        "if DEVICE != \"cpu\": # Solo cargar si hay GPU o si aceptamos la lentitud de CPU\n",
        "    print(f\"\\n--- Cargando modelo Whisper '{MODELO_A_PROBAR}' en {DEVICE} ---\")\n",
        "    start_time_load = time.time()\n",
        "    try:\n",
        "        # Carga directa usando la librer√≠a whisper\n",
        "        modelo_cargado = whisper.load_model(MODELO_A_PROBAR, device=DEVICE)\n",
        "        end_time_load = time.time()\n",
        "        tiempo_carga_modelo = end_time_load - start_time_load\n",
        "        print(f\"Modelo '{MODELO_A_PROBAR}' cargado en {tiempo_carga_modelo:.2f} segundos.\")\n",
        "\n",
        "        print(\"\\n>> ¬°REVISA AHORA los indicadores RAM y GPU RAM de Colab para ver el uso M√ÅXIMO durante la carga! <<\")\n",
        "        print(\"Salida de nvidia-smi (uso de VRAM actual):\")\n",
        "        !nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error cr√≠tico al cargar el modelo: {e}\")\n",
        "        modelo_cargado = None\n",
        "else:\n",
        "    print(\"Proceso detenido porque no se detect√≥ GPU o se eligi√≥ CPU (no recomendado para 'large').\")"
      ],
      "metadata": {
        "id": "-jnbn9UELeL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 5: Realizar la Transcripci√≥n\n",
        "\n",
        "Con el modelo cargado y el audio en formato WAV, realizamos la transcripci√≥n. Mediremos el tiempo y volveremos a observar el uso de recursos.\n",
        "\n",
        "**¬°Atenci√≥n!** Durante la ejecuci√≥n de esta celda:\n",
        "*   **Observa de nuevo los indicadores `RAM` y `GPU RAM`**. El pico de uso de VRAM suele ocurrir *durante* la transcripci√≥n.\n",
        "*   La opci√≥n `fp16` (definida en la Celda 6) controla si se usa precisi√≥n media (m√°s r√°pido, menos VRAM) o completa (predeterminada)."
      ],
      "metadata": {
        "id": "IpKHoXhrS6Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 12: Transcribir y Medir Tiempo/Recursos\n",
        "\n",
        "if modelo_cargado and ruta_audio_wav:\n",
        "    print(f\"\\n--- Transcribiendo {ruta_audio_wav.name} con '{MODELO_A_PROBAR}' (fp16={USE_FP16}) ---\")\n",
        "    start_time_transcribe = time.time()\n",
        "    try:\n",
        "        # Aseg√∫rate de pasar la ruta como string\n",
        "        audio_path_str = str(ruta_audio_wav)\n",
        "\n",
        "        # ¬°Llamada a la transcripci√≥n!\n",
        "        # verbose=None o False para menos salida en consola, True para detalles\n",
        "        resultado_transcripcion = modelo_cargado.transcribe(\n",
        "            audio_path_str,\n",
        "            language=config.TARGET_LANGUAGE, # Definido en config.py ('es')\n",
        "            initial_prompt=config.WHISPER_INITIAL_PROMPT, # Definido en config.py\n",
        "            fp16=USE_FP16,\n",
        "            verbose=None\n",
        "        )\n",
        "        end_time_transcribe = time.time()\n",
        "        tiempo_transcripcion = end_time_transcribe - start_time_transcribe\n",
        "        print(f\"Transcripci√≥n completada en {tiempo_transcripcion:.2f} segundos.\")\n",
        "\n",
        "        print(\"\\n>> ¬°REVISA AHORA los indicadores RAM y GPU RAM de Colab para ver el uso M√ÅXIMO durante la transcripci√≥n! <<\")\n",
        "        print(\"Salida de nvidia-smi (uso de VRAM actual post-transcripci√≥n):\")\n",
        "        !nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error cr√≠tico durante la transcripci√≥n: {e}\")\n",
        "        resultado_transcripcion = None\n",
        "else:\n",
        "    print(\"No se puede transcribir: el modelo no se carg√≥ o el archivo WAV no est√° listo.\")"
      ],
      "metadata": {
        "id": "Si5aPlumLiKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 6: Ver Resultados\n",
        "\n",
        "Mostramos un resumen de los tiempos medidos y el texto transcrito obtenido."
      ],
      "metadata": {
        "id": "YfB-VwNES_Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 14: Mostrar Resumen y Texto Transcrito\n",
        "\n",
        "print(\"\\n--- Resumen de la Ejecuci√≥n ---\")\n",
        "print(f\"Modelo: {MODELO_A_PROBAR}\")\n",
        "print(f\"Dispositivo: {DEVICE} (FP16={USE_FP16})\")\n",
        "if ruta_audio_original:\n",
        "  print(f\"Archivo Original: {ruta_audio_original.name}\")\n",
        "else:\n",
        "  print(\"Archivo Original: (Error en ruta)\")\n",
        "print(f\"Tiempo de Carga del Modelo: {tiempo_carga_modelo:.2f} s\")\n",
        "print(f\"Tiempo de Transcripci√≥n: {tiempo_transcripcion:.2f} s\")\n",
        "\n",
        "if resultado_transcripcion:\n",
        "    print(\"\\n--- Texto Transcrito ---\")\n",
        "    # Accedemos al texto dentro del diccionario resultado\n",
        "    texto_final = resultado_transcripcion.get(\"text\", \"Error: No se encontr√≥ texto en el resultado.\")\n",
        "    print(texto_final.strip()) # .strip() para quitar espacios iniciales/finales\n",
        "    print(\"-\" * 26) # Separador\n",
        "\n",
        "    # (Opcional) Descomenta para ver los segmentos individuales con tiempos\n",
        "    # print(\"\\n--- Segmentos Detallados ---\")\n",
        "    # segments = resultado_transcripcion.get(\"segments\", [])\n",
        "    # if segments:\n",
        "    #     for segment in segments:\n",
        "    #         start = segment.get('start', 0)\n",
        "    #         end = segment.get('end', 0)\n",
        "    #         text = segment.get('text', '')\n",
        "    #         print(f\"[{start:>7.2f}s -> {end:>7.2f}s] {text.strip()}\")\n",
        "    # else:\n",
        "    #     print(\"No se encontraron segmentos detallados en el resultado.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo se obtuvo resultado de la transcripci√≥n debido a errores previos.\")"
      ],
      "metadata": {
        "id": "q7y3AxzmMCIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso 7: Limpieza\n",
        "\n",
        "Finalmente, eliminamos el archivo WAV temporal que se cre√≥ durante la conversi√≥n."
      ],
      "metadata": {
        "id": "qa1vLZq2TG1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 16: Limpiar Archivo Temporal\n",
        "\n",
        "# Usar la funci√≥n de limpieza de audio_handler\n",
        "# para eliminar el archivo _temp_playback.wav si existe\n",
        "try:\n",
        "    if 'audio_handler' in sys.modules:\n",
        "        print(\"\\nLimpiando archivo WAV temporal...\")\n",
        "        audio_handler.cleanup_temp_wav()\n",
        "        print(\"Limpieza completada.\")\n",
        "    else:\n",
        "        print(\"M√≥dulo audio_handler no cargado, no se puede limpiar autom√°ticamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error durante la limpieza del archivo temporal: {e}\")"
      ],
      "metadata": {
        "id": "vKHQbXrRMVpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusi√≥n del Experimento\n",
        "\n",
        "¬°Has ejecutado Whisper `large` en una GPU!\n",
        "\n",
        "*   Compara los **tiempos de carga y transcripci√≥n** con lo que experimentar√≠as en CPU.\n",
        "*   Analiza el **uso de VRAM y RAM** que observaste. ¬øCabe en GPUs comunes?\n",
        "*   Revisa la **calidad del texto transcrito**. ¬øCumple tus expectativas?\n",
        "\n",
        "Puedes volver a ejecutar las celdas (especialmente desde la Celda 6) cambiando el archivo de audio, el modelo (`medium`, `small`...) o el par√°metro `USE_FP16` para comparar resultados."
      ],
      "metadata": {
        "id": "etmR7DmTTSNH"
      }
    }
  ]
}